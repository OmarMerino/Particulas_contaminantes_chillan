{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415e5324-acda-4f67-9771-6a7ba4edae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7628af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PM 2.5 ESTACIONES INIA Y PUREN\n",
    "d_pm25_inia = pd.read_csv('../data/raw/pm2.5_INIA_080913_230807.csv',sep=';', thousands=None, decimal=',')\n",
    "d_pm25_puren = pd.read_csv('../data/raw/pm2.5_puren_120315_230808.csv',sep=';', thousands=None, decimal=',')\n",
    "\n",
    "#PM10 ESTACIONES INIA Y PUREN\n",
    "d_pm10_inia = pd.read_csv('../data/raw/pm10_INIA_080101_230807.csv',sep=';', thousands=None, decimal=',')\n",
    "d_pm10_puren = pd.read_csv('../data/raw/pm10_puren_120316_230807.csv',sep=';', thousands=None, decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d554b4ff-b05a-4b2b-9e35-3cd4f2a4b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataframes_dict.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exportamos diccionario\n",
    "dataframes_dict = {\n",
    "    'pm_2.5_inia': d_pm25_inia,\n",
    "    'pm_2.5_puren': d_pm25_puren,\n",
    "    'pm_10_inia': d_pm10_inia,\n",
    "    'pm_10_puren': d_pm10_puren\n",
    "}\n",
    "\n",
    "\n",
    "for clave, df in dataframes_dict.items():\n",
    "    # path para el guardado de archivos\n",
    "    path = '../data/processed/{}.csv'.format(clave)\n",
    "\n",
    "    #convertimos FECHA (YYMMDD) a string\n",
    "    df['FECHA (YYMMDD)'] = df['FECHA (YYMMDD)'].astype(str)\n",
    "\n",
    "    #rellenamos con 0 para dar uniformidad\n",
    "    df['FECHA (YYMMDD)'] = df['FECHA (YYMMDD)'].str.zfill(6)\n",
    "\n",
    "    # eliminamos el campo hora\n",
    "    df = df.drop('HORA (HHMM)', axis=1)\n",
    "\n",
    "    #dar formato date\n",
    "    df['FECHA (YYMMDD)'] = pd.to_datetime(df['FECHA (YYMMDD)'], format='%y%m%d')\n",
    "\n",
    "    # filtramos solamente registros validados\n",
    "    df = df[df['Registros validados'].notnull()]\n",
    "\n",
    "    #eliminamos registros preliminares\n",
    "    df = df.drop('Registros preliminares', axis=1)\n",
    "\n",
    "    #eliminamos registros no validados\n",
    "    df = df.drop('Registros no validados', axis=1)\n",
    "\n",
    "    #eliminamos columnas 'Unnamed'\n",
    "    df.drop('Unnamed: 5', axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    #df['Registros validados'] = df['Registros validados'].str.replace('.', '')  # elimina el separador de miles\n",
    "    #df['Registros validados'] = df['Registros validados'].str.replace(',', '.') # convierte el separador decimal\n",
    "    # df['Registros validados'] = df['Registros validados'].astype(float)\n",
    "    # df['columna_con_comas'] = df['columna_con_comas'].str.replace(',', '.').astype(float)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # #POR CADA FECHA QUE SE REPITA SE DEJA EL PROMEDIO DE TODOS LOS VALORES DE LA FECHA COMO UNA UNICA TUPLA DEBIDO AL REGISTRO HORARIO DE UN DF EN PARTICULAR\n",
    "    df = df.groupby('FECHA (YYMMDD)')['Registros validados'].mean().reset_index()\n",
    "\n",
    "\n",
    "    #renombramos columas\n",
    "    df = df.rename(columns={\n",
    "    'FECHA (YYMMDD)': 'fecha',\n",
    "    'Registros validados': 'registro'\n",
    "    })\n",
    "\n",
    "\n",
    "    #HACEMOS EFECTIVO EL CAMBIO\n",
    "    dataframes_dict[clave] = df\n",
    "\n",
    "    #guardamos nuevo archivo csv\n",
    "    df.to_csv(path, sep=';',index=False, float_format='%.4f', decimal=',')\n",
    "\n",
    "joblib.dump(dataframes_dict, 'dataframes_dict.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b22092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm_2.5_inia 0\n",
      "pm_2.5_puren 0\n",
      "pm_10_inia 0\n",
      "pm_10_puren 0\n"
     ]
    }
   ],
   "source": [
    "for clave, valor in dataframes_dict.items():\n",
    "    num_duplicados = valor.duplicated(subset=['fecha']).sum()\n",
    "    print(clave, num_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db5001d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          fecha    registro\n",
      "3715 2023-03-31   22.666667\n",
      "1477 2017-01-27  739.350000\n"
     ]
    }
   ],
   "source": [
    "indice_max = dataframes_dict['pm_2.5_puren'].idxmax()\n",
    "fila_max = dataframes_dict['pm_2.5_puren'].loc[indice_max]\n",
    "print(fila_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47a81459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha       2023-03-31\n",
      "registro        739.35\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_check = pd.read_csv('../data/processed/pm_2.5_puren.csv',sep=';', thousands=None, decimal=',')\n",
    "print(df_check.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d4d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
